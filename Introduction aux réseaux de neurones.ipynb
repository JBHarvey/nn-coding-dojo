{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction aux réseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from dojo.dataset import Cifar10Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du dataset\n",
    "\n",
    "Durant ce dojo, nous utiliserons le dataset CIFAR10. Ce dataset comprend 60000 images RGB 32 par 32 de 10 classes différentes:\n",
    "\n",
    "0. airplane\n",
    "1. automobile\n",
    "2. bird\n",
    "3. cat\n",
    "4. deer\n",
    "5. dog\n",
    "6. frog\n",
    "7. horse\n",
    "8. ship\n",
    "9. truck\n",
    "\n",
    "Il existe également le dataset CIFAR100, qui a lui 100 classes distinctes. Pour plus de détails, voir le [site officiel](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "Évaluez les cellules suivante pour télécharger le jeu de données. Normalement, vous devriez voir qu'il y a 50000 images dans les données d'entraînement et 10000 images dans les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cifar10 = Cifar10Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cifar10.x_train.shape)\n",
    "print(cifar10.y_train.shape)\n",
    "print(cifar10.x_test.shape)\n",
    "print(cifar10.y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(cifar10.y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(cifar10.x_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Le problème de classification\n",
    "\n",
    "Regardons la première image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cifar10.x_train[0])\n",
    "print(cifar10.y_train[0])\n",
    "plt.imshow(cifar10.x_train[0].astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Cette image est comprise par un humain comme étant une grenouille. Par contre, pour un ordinateur, cette image n'est rien de plus q'un tableau de 32 x 32 x 3 nombres à virgule flottante. Le problème de classification d'image est donc le suivant:\n",
    " \n",
    " \n",
    "> Étant donné des images $x_i$ et leurs étiquettes $y_i$, trouvez la fonction $f(X): x \\rightarrow y$ qui maximise le bon nombre d'associations entre les images et les étiquettes et qui se généralise à des images inconnues.\n",
    "\n",
    "\n",
    "La généralisation est un élément primordial en machine learning. C'est bien beau d'être capable de classifier correctement les données d'entraînement, mais il faut à tout pris éviter le phénomène d'*overfitting*. L'exemple classique est de trouver la courbe qui passe par une série de points. Si on a $n$ points, il est possible de trouver un polynôme de degré $n + 1$ qui passe parfaitement par tous les points. Par contre, cette courbe risque de moins bien performer qu'un modèle plus simple. pour passer à travers les autres points de la distribution que l'on n'as pas encore observé.\n",
    "\n",
    "![overfitting](https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Overfitted_Data.png/300px-Overfitted_Data.png)\n",
    "\n",
    "\n",
    "Généralement, en machine learning, on sépare les données en deux groupes: *training* et *testing*. Ainsi, on peut évaluer la performance du modèle sur les données inconnues en utilisant des données qui n'ont pas servi à l'entraînement.\n",
    "\n",
    "#### Classification linéaire\n",
    "\n",
    "On peut décomposer la fonction $f$ en plusieurs fonctions. Au lieu d'avoir une fonction unique qui retourne directment l'étiquette $y$ de l'image, on peut avoir une fonction par classe du dataset et chaque fonction retourne le score associé à l'image en entrée qui indique à quel point il est probable que l'image est cette classe. Par exemple, si le dataset a seulement deux classes, 0 pour chien et 1 pour chat, nous aurions deux fonctions $f_0(X)$ et $f_1(X)$. Pour une image donnée $x_i$, si on a $f_0(x_i) = 0.6$ et $f_1(x_i) = 0.2$, on en déduit que l'image $x_i$  est un chien, car selon les fonctions, il est plus probable que l'image soit un chien. Voici une représentation visuelle des fonction $f_j(x)$. À noter, la figure est en 2D, mais dans le cas réel, les fonctions séparent les images dans un espace à $32 \\times 32 \\times 3 = 3072$ dimensions.\n",
    "\n",
    "![classification figure](http://cs231n.github.io/assets/pixelspace.jpeg)\n",
    "\n",
    "La classification linéaire est un modèle très simple pour représenter les fonctions $f_j(x)$. La formulation est la suivante:\n",
    "\n",
    "$$\n",
    "f_j(x) = w_j \\cdot x + b_j\n",
    "$$\n",
    "\n",
    "> **NOTE** Pour simplifier les calculs, $x$ est redimensionné en un vecteur de 3072 éléments. Ainsi, il est très facile d'associer un point à chaque pixel et multiplier ces points à $x$, puisque cela se résume en un produit scalaire.\n",
    "\n",
    "Dans la formule précédente, le vecteur $w_j$ représente les poids (ou *weights* en anglais) à associer à chaque pixel de l'image $x$ et $b_j$ est un scalaire qui représente le biais, c'est-à-dire si à priori il est plus probable d'observer la classe $j$.\n",
    "\n",
    "\n",
    "Pour que le calcul soit plus efficace, il est possible de calculer tous les scores $f_j(x)$ en même temps. Il suffit de mettre tous les vecteurs $w_j$ dans une matrice $W$ où chaque ligne $j$ est $w_j$ et de faire le produit matriciel $Wx$, puis additionner un vecteur $b$ qui contient les biais. Cela revient exactement au même que de faire les produit scalaires séparemment. Voici une représentation visuelle cette opération:\n",
    "\n",
    "![weight matrix](http://cs231n.github.io/assets/imagemap.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
